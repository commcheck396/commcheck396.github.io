---
layout: post
title: 'Transformeræ¨¡å‹'
date: 2022-2-16
author: ä¸æ˜¾ç”µæ€§
cover: 'http://commcheck396.github.io/assets/img/2022_2_14/transformer.png'
tags: ML Python
---
# Attention is all U need


åœ¨äº†è§£transformeræ¨¡å‹ä¹‹å‰ï¼Œæˆ‘ä»¬é¦–å…ˆè¦ææ¸…self-attentionçš„æ¦‚å¿µã€‚ 
Self-attentionï¼Œè¾“å…¥æ˜¯ä¸€ä¸²vector setï¼Œè¾“å‡ºäº¦ç„¶ï¼ŒRNNç½‘ç»œåŒæ ·å¯ä»¥å®ç°ç±»ä¼¼çš„äº‹æƒ…è€Œä¸”æ›´å¥½æ­å»ºï¼Œä½†æ˜¯Self-attentionå¯ä»¥å®ç°æ•°æ®çš„å¹¶è¡Œå¤„ç†ï¼Œè€ŒRNNä»…å¯ä»¥å®ç°ä¸²è¡Œï¼Œæ‰€ä»¥ä¼˜å…ˆç ”ç©¶è¿™ä¸ªæ•ˆç‡è¾ƒé«˜çš„æ–¹å‘äº†ï¼Œä¹Ÿå¯èƒ½ä¼šå»å­¦ä¸€ä¸‹RNNï¼Œ~~å› ä¸ºè¿™ä¸ªæ­å»ºèµ·æ¥å®åœ¨æ˜¯å¤ªéº»çƒ¦äº†~~ï¼Œæ”¾åœ¨Pytorchä¾¿ç­¾ä¸­å§ã€‚   

Self-attentionå…¶å®ä¸éš¾ç†è§£ï¼Œç®€è€Œè¨€ä¹‹å°±æ˜¯ç”¨å„ç§æ–¹æ³•åœ¨è¾“å…¥çš„å‘é‡é—´æ‰¾å½¼æ­¤çš„å…³ç³»Î±ï¼Œç„¶åå¯¹è¾“å…¥å†…å®¹è¿›è¡Œé¢„æµ‹ï¼Œè¾“å‡ºä¸€ä¸ªvector setã€‚ç›´æ¥ä¸Šå›¾ã€‚
![pic from internet](http://commcheck396.github.io/assets/img/2022_2_14/selfattention.jpg)
è¿™æ˜¯self-attentionçš„æ•´ä¸ªæµç¨‹ï¼Œå¹¶éç¥ç»ç½‘ç»œï¼è‹¥è¦è¿›è¡Œæœºå™¨å­¦ä¹ è®­ç»ƒï¼Œè¿˜éœ€è¦æ­å»ºç¥ç»ç½‘ç»œï¼Œè¿™ä¹Ÿä¾¿æœ‰äº†transformeræ¨¡å‹ã€‚  
åœ¨åŸå§‹è®ºæ–‡ä¸­Self-Attentionä¸­æ²¡æœ‰è€ƒè™‘ä½ç½®ä¿¡æ¯ï¼Œä¸å¦¨åŠ ä¸€ä¸ªeiæ¥è¡¨ç¤ºä½ç½®ä¿¡æ¯ï¼Œæ€ä¹ˆç†è§£å‘¢ï¼Œå¯ä»¥ç†è§£ä¸ºåœ¨xiå‘é‡ä¸ŠåŠ äº†ä¸€ä¸ªone-hotè¡¨ç¤ºçš„piï¼Œç„¶åç»è¿‡è®¡ç®—å‘ç°eiå¹¶ä¸å½±å“åŸæ¥çš„å‘é‡ï¼Œæ‰€ä»¥åŠ å…¥è¿™ä¸ªä½ç½®ä¿¡æ¯ä¸ä»…ä¸ä¼šå½±å“å·²æœ‰çš„æ•°æ®ï¼Œè¿˜èƒ½åœ¨è¾“å…¥ä¸­åŠ å…¥æœ‰å…³ä½ç½®çš„ä¿¡æ¯ï¼Œå¯è°“ä¸€ä¸¾ä¸¤å¾—ã€‚
![pic from internet](http://commcheck396.github.io/assets/img/2022_2_14/position.png)

å…¶å®ï¼Œtransformeræ¨¡å‹å’Œä¸Šè¿°è¿‡ç¨‹å¹¶éå®Œå…¨ç›¸å…³ï¼Œä¸ä¹‹æ›´ä¸ºç›¸å…³çš„æ˜¯ä¸‹æ–¹çš„multihead
![pic from internet](http://commcheck396.github.io/assets/img/2022_2_14/multi.jpg)
çœ‹è¿‡äº†æ•´ä¸ªè·¯ç¨‹ï¼Œä¸éš¾å‘ç°æˆ‘ä»¬éœ€è¦å­¦ä¹ çš„å‚æ•°ä¸€å…±å°±ä¸‹é¢å‡ ä¸ªå„¿
![pic from internet](http://commcheck396.github.io/assets/img/2022_2_14/parameter.jpg)
Self-attentionä¹Ÿå°±è¿™ä¹ˆå¤šï¼Œä¸‹é¢è¿›å…¥æ­£é¢˜transformerã€‚

## Transformerå®ç°
è¿™ä¸ªæ¨¡å‹å¯ä»¥çœ‹æˆæ˜¯ä¸€ä¸ªé»‘ç®±æ“ä½œã€‚åœ¨æœºå™¨ç¿»è¯‘ä¸­ï¼Œå°±æ˜¯è¾“å…¥ä¸€ç§è¯­è¨€ï¼Œè¾“å‡ºå¦ä¸€ç§è¯­è¨€ã€‚
![pic from internet](http://commcheck396.github.io/assets/img/2022_2_14/transformer.png)
è¿™ä¸ªé»‘ç®±æ˜¯ç”±ç¼–ç ç»„ä»¶ã€è§£ç ç»„ä»¶å’Œå®ƒä»¬ä¹‹é—´çš„è¿æ¥ç»„æˆã€‚

![pic from internet](http://commcheck396.github.io/assets/img/2022_2_14/blackbox.png)

ç¼–ç ç»„ä»¶éƒ¨åˆ†ç”±ä¸€å †ç¼–ç å™¨ï¼ˆencoderï¼‰æ„æˆï¼ˆè®ºæ–‡ä¸­æ˜¯å°†6ä¸ªç¼–ç å™¨å åœ¨ä¸€èµ·ï¼‰ã€‚è§£ç ç»„ä»¶éƒ¨åˆ†ä¹Ÿæ˜¯ç”±ç›¸åŒæ•°é‡ï¼ˆä¸ç¼–ç å™¨å¯¹åº”ï¼‰çš„è§£ç å™¨ï¼ˆdecoderï¼‰ç»„æˆçš„ã€‚æ‰€æœ‰çš„ç¼–ç å™¨åœ¨ç»“æ„ä¸Šéƒ½æ˜¯ç›¸åŒçš„ï¼Œä½†å®ƒä»¬æ²¡æœ‰å…±äº«å‚æ•°ã€‚æ¯ä¸ªè§£ç å™¨éƒ½å¯ä»¥åˆ†è§£æˆä¸¤ä¸ªå­å±‚ã€‚

![pic from internet](http://commcheck396.github.io/assets/img/2022_2_14/bianmaqi.png)

ä»ç¼–ç å™¨è¾“å…¥çš„å¥å­é¦–å…ˆä¼šç»è¿‡ä¸€ä¸ªä¸Šæ–‡æåˆ°çš„è‡ªæ³¨æ„åŠ›ï¼ˆself-attentionï¼‰å±‚ï¼Œè¿™å±‚å¸®åŠ©ç¼–ç å™¨åœ¨å¯¹æ¯ä¸ªå•è¯ç¼–ç æ—¶å…³æ³¨è¾“å…¥å¥å­çš„å…¶ä»–å•è¯ã€‚  

è‡ªæ³¨æ„åŠ›å±‚çš„è¾“å‡ºä¼šä¼ é€’åˆ°å‰é¦ˆï¼ˆfeed-forwardï¼‰ç¥ç»ç½‘ç»œä¸­ã€‚æ¯ä¸ªä½ç½®çš„å•è¯å¯¹åº”çš„å‰é¦ˆç¥ç»ç½‘ç»œéƒ½å®Œå…¨ä¸€æ ·ã€‚  

è§£ç å™¨ä¸­ä¹Ÿæœ‰ç¼–ç å™¨çš„è‡ªæ³¨æ„åŠ›ï¼ˆself-attentionï¼‰å±‚å’Œå‰é¦ˆï¼ˆfeed-forwardï¼‰å±‚ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œè¿™ä¸¤ä¸ªå±‚ä¹‹é—´è¿˜æœ‰ä¸€ä¸ªæ³¨æ„åŠ›å±‚ï¼Œç”¨æ¥å…³æ³¨è¾“å…¥å¥å­çš„ç›¸å…³éƒ¨åˆ†ï¼ˆå’Œseq2seqæ¨¡å‹çš„æ³¨æ„åŠ›ä½œç”¨ç›¸ä¼¼ï¼‰ã€‚  

Transformer çš„ Decoderçš„è¾“å…¥ä¸Encoderçš„è¾“å‡ºå¤„ç†æ–¹æ³•æ­¥éª¤æ˜¯ä¸€æ ·åœ°ï¼Œä¸€ä¸ªæ¥å—sourceæ•°æ®ï¼Œä¸€ä¸ªæ¥å—targetæ•°æ®ï¼Œä¸¾ä¸ªä¾‹å­ï¼šEncoderæ¥å—è‹±æ–‡"Tom chase Jerry"ï¼ŒDecoderæ¥å—ä¸­æ–‡"æ±¤å§†è¿½é€æ°ç‘"ã€‚åªæ˜¯åœ¨æœ‰targetæ•°æ®æ—¶ä¹Ÿå°±æ˜¯åœ¨è¿›è¡Œæœ‰ç›‘ç£è®­ç»ƒæ—¶æ‰ä¼šæ¥å—Outputs Embeddingï¼Œè¿›è¡Œé¢„æµ‹æ—¶åˆ™ä¸ä¼šæ¥æ”¶ã€‚  


ä¹‹åå°±è¦å¼•å…¥æˆ‘ä»¬çš„å¼ é‡äº†ï¼Œæˆ‘ä»¬é¦–å…ˆå°†æ¯ä¸ªè¾“å…¥å•è¯é€šè¿‡è¯åµŒå…¥ç®—æ³•è½¬æ¢ä¸ºè¯å‘é‡ï¼Œæ¯ä¸ªå•è¯éƒ½è¢«åµŒå…¥ä¸º512ç»´çš„å‘é‡ã€‚

è¯åµŒå…¥è¿‡ç¨‹åªå‘ç”Ÿåœ¨æœ€åº•å±‚çš„ç¼–ç å™¨ä¸­ã€‚æ‰€æœ‰çš„ç¼–ç å™¨éƒ½æœ‰ä¸€ä¸ªç›¸åŒçš„ç‰¹ç‚¹ï¼Œå³å®ƒä»¬æ¥æ”¶ä¸€ä¸ªå‘é‡åˆ—è¡¨ï¼Œåˆ—è¡¨ä¸­çš„æ¯ä¸ªå‘é‡å¤§å°ä¸º512ç»´ã€‚åœ¨åº•å±‚ï¼ˆæœ€å¼€å§‹ï¼‰ç¼–ç å™¨ä¸­å®ƒå°±æ˜¯è¯å‘é‡ï¼Œä½†æ˜¯åœ¨å…¶ä»–ç¼–ç å™¨ä¸­ï¼Œå®ƒå°±æ˜¯ä¸‹ä¸€å±‚ç¼–ç å™¨çš„è¾“å‡ºï¼ˆä¹Ÿæ˜¯ä¸€ä¸ªå‘é‡åˆ—è¡¨ï¼‰ã€‚å‘é‡åˆ—è¡¨å¤§å°æ˜¯æˆ‘ä»¬å¯ä»¥è®¾ç½®çš„è¶…å‚æ•°â€”â€”ä¸€èˆ¬æ˜¯æˆ‘ä»¬è®­ç»ƒé›†ä¸­æœ€é•¿å¥å­çš„é•¿åº¦ã€‚  

æˆ‘ä»¬è¿˜éœ€è¦ç»™æ¯ä¸ªwordçš„è¯å‘é‡æ·»åŠ ä½ç½®ç¼–ç positional encodingï¼Œä¸ºä»€ä¹ˆéœ€è¦æ·»åŠ ä½ç½®ç¼–ç å‘¢ï¼Ÿ  

é¦–å…ˆå’±ä»¬çŸ¥é“ï¼Œä¸€å¥è¯ä¸­åŒä¸€ä¸ªè¯ï¼Œå¦‚æœè¯è¯­å‡ºç°ä½ç½®ä¸åŒï¼Œæ„æ€å¯èƒ½å‘ç”Ÿç¿»å¤©è¦†åœ°çš„å˜åŒ–ï¼Œå°±æ¯”å¦‚ï¼šæˆ‘æ¬ ä»–100W å’Œ ä»–æ¬ æˆ‘100Wã€‚è¿™ä¸¤å¥è¯çš„æ„æ€ä¸€ä¸ªåœ°ç‹±ä¸€ä¸ªå¤©å ‚ã€‚å¯è§è·å–è¯è¯­å‡ºç°åœ¨å¥å­ä¸­çš„ä½ç½®ä¿¡æ¯æ˜¯ä¸€ä»¶å¾ˆé‡è¦çš„äº‹æƒ…ã€‚  

è¿™positional encodingçš„è·å–ä¹Ÿæ˜¯ä¸€é—¨å­¦é—®ï¼Œä¸€èˆ¬æˆ‘ä»¬ä¼šç”¨ä¸‹é¢ä¸¤ä¸ªå…¬å¼æ¥è·å–ã€‚  

å•¥ï¼Ÿä½ é—®ä¸ºå•¥ï¼Ÿåˆ«é—®ï¼Œé—®å°±æ˜¯å¤åœ£å…ˆè´¤ã€‚

![pic from internet](http://commcheck396.github.io/assets/img/2022_2_14/positionf.png)

### encoder

self-attentionç»“æ„å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![pic from internet](http://commcheck396.github.io/assets/img/2022_2_14/encoderlayer.png)

ä½†åœ¨encoder layerä¸­è¿ç”¨çš„æ¶æ„å¹¶éè¿™ä¸€ä¸ªï¼Œè€Œæ˜¯Multi-Head Attentionï¼Œè¿™ä¸ªé—®é¢˜åœ¨ä¸Šæ–‡ä¹Ÿæœ‰è®¨è®ºè¿‡ï¼Œå…¶å®å®ƒå°±æ˜¯åœ¨self-attentionçš„åŸºç¡€ä¸Šï¼Œå¯¹äºè¾“å…¥çš„embeddingçŸ©é˜µæœ‰å¤šä¸ªçŸ©é˜µè¿›è¡Œæ•°æ®çš„å¤„ç†ï¼Œå¹¶åœ¨å¾—åˆ°å¤šä¸ªç»“æœåå†è¿›è¡Œé™ç»´ï¼Œå¾—åˆ°æœ€ç»ˆç»“æœã€‚  

è€Œè¿™ä¸ªé™ç»´æ“ä½œï¼Œå±•å¼€æ¥è¯´å°±æ˜¯**Addï¼†Normalize**  

ç®€å•æ¥è¯´ï¼ŒAddæ“ä½œçš„ä½œç”¨å°±æ˜¯åœ¨è¾“å…¥ä¸­åŠ å…¥æ®‹å·®å—ï¼Œé˜²æ­¢ç¥ç»ç½‘ç»œç”±äºlayerè¿‡å¤šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­äº§ç”Ÿé€€åŒ–é—®é¢˜ï¼Œè€Œè¿™ä¸ªæ®‹å·®å—æ¶‰åŠåˆ°resnetæ–¹é¢çš„çŸ¥è¯†ï¼Œå¯¹è¿™æ–¹é¢æˆ‘äº†è§£ç”šå°‘ï¼Œæ‰€ä»¥å°±å…ˆä¸æ±‚ç”šè§£ä¸€ä¸‹ï¼Œå¼ºè¡Œè®°ä¸€ä¸‹è¿™ä¸ªä¸œè¥¿å§ã€‚  

Normalizationåˆ™æ˜¯åœ¨ä¹‹å‰å¾ˆå¸¸è§çš„å½’ä¸€åŒ–æ•°æ®çš„æ‰‹æ®µï¼Œèƒ½å¤ŸåŠ å¿«è®­ç»ƒçš„é€Ÿåº¦ï¼Œæé«˜è®­ç»ƒçš„ç¨³å®šæ€§ï¼Œä¹Ÿèƒ½è®©è®­ç»ƒæ•°æ®çœ‹èµ·æ¥æ›´åŠ è§„åˆ™ã€‚  

ä½†åœ¨transformerä¸­ï¼Œè¿›è¡ŒNormalizationçš„æ‰‹æ®µå¹¶éä¹‹å‰æåˆ°çš„Batch Normalizationï¼Œè€Œæ˜¯ä¸€ç§æ–°çš„Normalizationæ–¹å¼ï¼Œç§°ä¸ºLayer Normalizationã€‚äºŒè€…çš„å·®åˆ«å¦‚ä¸‹å›¾æ‰€ç¤º

![pic from internet](http://commcheck396.github.io/assets/img/2022_2_14/normal.png)

Layer Normalizationæ˜¯åœ¨åŒä¸€ä¸ªæ ·æœ¬ä¸­ä¸åŒç¥ç»å…ƒä¹‹é—´è¿›è¡Œå½’ä¸€åŒ–ï¼Œè€ŒBatch Normalizationæ˜¯åœ¨åŒä¸€ä¸ªbatchä¸­ä¸åŒæ ·æœ¬ä¹‹é—´çš„åŒä¸€ä½ç½®çš„ç¥ç»å…ƒä¹‹é—´è¿›è¡Œå½’ä¸€åŒ–ã€‚  

Batch Normalizationæ˜¯å¯¹äºç›¸åŒçš„ç»´åº¦è¿›è¡Œå½’ä¸€åŒ–ï¼Œä½†æ˜¯å’±ä»¬NLPä¸­è¾“å…¥çš„éƒ½æ˜¯è¯å‘é‡ï¼Œä¸€ä¸ª300ç»´çš„è¯å‘é‡ï¼Œå•ç‹¬å»åˆ†æå®ƒçš„æ¯ä¸€ç»´æ˜¯æ²¡æœ‰æ„ä¹‰åœ°ï¼Œåœ¨æ¯ä¸€ç»´ä¸Šè¿›è¡Œå½’ä¸€åŒ–ä¹Ÿæ˜¯é€‚åˆåœ°ï¼Œå› æ­¤è¿™é‡Œé€‰ç”¨çš„æ˜¯Layer Normalizationã€‚  

è§£å†³äº†Addï¼†Normalizeçš„é—®é¢˜ï¼Œæˆ‘ä»¬è¿˜é¢ä¸´ç€æœ€åä¸€ä¸ªé—®é¢˜ï¼Œå°±æ˜¯å‰é¦ˆç¥ç»ç½‘ç»œFeed-Forward Networksçš„é—®é¢˜ã€‚  

è¿™ä¸€éƒ¨åˆ†å°±æ¯”è¾ƒç†Ÿæ‚‰äº†ï¼Œåœ¨ä¹‹å‰çš„CNNåˆ†æå›¾ç‰‡ä¸­æˆ‘ä»¬æ›¾ç»ç”¨è¿‡2dçš„convï¼Œè¿™æ¬¡ç”±äºå•è¯çš„å½¢å¼ä¸ºvectorï¼Œæ¢æˆ1då°±å¥½äº†ï¼Œæ¢æ±¤ä¸æ¢è¯ã€‚è¿™ä¸€éƒ¨åˆ†çš„åˆ†ææ”¾åˆ°ä¹‹åçš„ä»£ç è§£æéƒ¨åˆ†å§ã€‚  

åˆ°è¿™é‡Œå¯¹encoder layerçš„åˆ†æå°±å·®ä¸å¤šç»“æŸäº†ï¼Œè‡³äºencoderï¼Œå°±æ˜¯æ•°ä¸ªencoder layeré¦–å°¾ç›¸è¿ï¼Œæ— ä»–ã€‚  

å…¶å®decoderçš„ç»“æ„ä¸encoderçš„ç»“æ„ç±»ä¼¼ï¼Œå”¯ä¸€å¤šå‡ºæ¥çš„ä¸€éƒ¨åˆ†å°±æ˜¯å…¶ä¸­åŒ…å«maskæ“ä½œã€‚  

![pic from internet](http://commcheck396.github.io/assets/img/2022_2_14/decoder.png)

maskæ“ä½œç®€è€Œè¨€ä¹‹å°±æ˜¯å¯¹æ•°æ®è¿›è¡ŒæŸç§æ„ä¹‰ä¸Šçš„è¦†ç›–ï¼Œä¸è¦è®©æ¨¡å‹æ¥è§¦åˆ°å¤šä½™æˆ–æ˜¯é”™è¯¯åœ°ä¿¡æ¯ï¼Œå¯¹è®­ç»ƒè¿‡ç¨‹é€ æˆå½±å“ã€‚ 

maskåˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼Œç¬¬ä¸€éƒ¨åˆ†æ˜¯é’ˆå¯¹paddingéƒ¨åˆ†çš„maskï¼Œç”±äºè¾“å…¥çš„å¥å­çš„é•¿åº¦çš„ä¸ç»Ÿä¸€æ€§ï¼Œæˆ‘ä»¬éœ€è¦paddingæ¥è¿›è¡Œè¡¥å…¨ï¼Œä½¿æ•´ä¸ªå¥å­è®­ç»ƒé›†å¯ä»¥ç»„æˆä¸€ä¸ªçŸ©é˜µï¼Œä½†åœ¨åç»­è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œç¥ç»ç½‘ç»œå¹¶ä¸çŸ¥é“å“ªä¸€éƒ¨åˆ†æ˜¯çœŸå®çš„æ•°æ®ï¼Œå“ªä¸€éƒ¨åˆ†æ˜¯è¡¥çš„paddingï¼Œä¸ºäº†é˜²æ­¢paddingä¸Šçš„æ•°æ®å¯¹ç¥ç»ç½‘ç»œçš„è®­ç»ƒé€ æˆå½±å“ï¼Œæ‰€ä»¥å¯¹å…¶è¿›è¡Œmaskæ“ä½œè¦†ç›–ã€‚å…·ä½“æ¥è¯´ï¼Œå°±æ˜¯ç»™åœ¨è¾ƒçŸ­çš„åºåˆ—åé¢å¡«å…… 0ã€‚ä½†æ˜¯å¦‚æœè¾“å…¥çš„åºåˆ—å¤ªé•¿ï¼Œåˆ™æ˜¯æˆªå–å·¦è¾¹çš„å†…å®¹ï¼ŒæŠŠå¤šä½™çš„ç›´æ¥èˆå¼ƒã€‚å› ä¸ºè¿™äº›å¡«å……çš„ä½ç½®ï¼Œå…¶å®æ˜¯æ²¡ä»€ä¹ˆæ„ä¹‰çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬çš„attentionæœºåˆ¶ä¸åº”è¯¥æŠŠæ³¨æ„åŠ›æ”¾åœ¨è¿™äº›ä½ç½®ä¸Šï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦è¿›è¡Œä¸€äº›å¤„ç†ã€‚  

å…·ä½“çš„åšæ³•æ˜¯ï¼ŒæŠŠè¿™äº›ä½ç½®çš„å€¼åŠ ä¸Šä¸€ä¸ªéå¸¸å¤§çš„è´Ÿæ•°(è´Ÿæ— ç©·)ï¼Œè¿™æ ·çš„è¯ï¼Œç»è¿‡ softmaxï¼Œè¿™äº›ä½ç½®çš„æ¦‚ç‡å°±ä¼šæ¥è¿‘0ï¼ï¼ˆåœ¨ä¸‹å›¾çš„ä¾‹å­ä¸­ï¼ŒçŸ©é˜µä¸º1çš„ä½ç½®ä¸ºmaskè¦è¦†ç›–çš„ä½ç½®ï¼‰ 

![pic from internet](http://commcheck396.github.io/assets/img/2022_2_14/padding.png)


ç¬¬äºŒéƒ¨åˆ†æ˜¯sequence maskï¼Œsequence mask æ˜¯ä¸ºäº†ä½¿å¾— decoder ä¸èƒ½çœ‹è§æœªæ¥çš„ä¿¡æ¯ã€‚å¯¹äºä¸€ä¸ªåºåˆ—ï¼Œåœ¨ time_step ä¸º t çš„æ—¶åˆ»ï¼Œæˆ‘ä»¬çš„è§£ç è¾“å‡ºåº”è¯¥åªèƒ½ä¾èµ–äº t æ—¶åˆ»ä¹‹å‰çš„è¾“å‡ºï¼Œè€Œä¸èƒ½ä¾èµ– t ä¹‹åçš„è¾“å‡ºã€‚å› æ­¤æˆ‘ä»¬éœ€è¦æƒ³ä¸€ä¸ªåŠæ³•ï¼ŒæŠŠ t ä¹‹åçš„ä¿¡æ¯ç»™éšè—èµ·æ¥ã€‚è¿™åœ¨è®­ç»ƒçš„æ—¶å€™æœ‰æ•ˆï¼Œå› ä¸ºè®­ç»ƒçš„æ—¶å€™æ¯æ¬¡æˆ‘ä»¬æ˜¯å°†targetæ•°æ®å®Œæ•´è¾“å…¥è¿›decoderä¸­åœ°ï¼Œé¢„æµ‹æ—¶ä¸éœ€è¦ï¼Œé¢„æµ‹çš„æ—¶å€™æˆ‘ä»¬åªèƒ½å¾—åˆ°å‰ä¸€æ—¶åˆ»é¢„æµ‹å‡ºçš„è¾“å‡ºã€‚  

é‚£ä¹ˆå…·ä½“æ€ä¹ˆåšå‘¢ï¼Ÿä¹Ÿå¾ˆç®€å•ï¼šäº§ç”Ÿä¸€ä¸ªä¸Šä¸‰è§’çŸ©é˜µï¼Œä¸Šä¸‰è§’çš„å€¼å…¨ä¸º0ã€‚æŠŠè¿™ä¸ªçŸ©é˜µä½œç”¨åœ¨æ¯ä¸€ä¸ªåºåˆ—ä¸Šï¼Œå°±å¯ä»¥è¾¾åˆ°æˆ‘ä»¬çš„ç›®çš„ã€‚

![pic from internet](http://commcheck396.github.io/assets/img/2022_2_14/sequence.png)

å‰©ä¸‹çš„ä¸åŒï¼Œå°±åªå‰©ä¸‹åœ¨decoderçš„è¾“å‡ºéƒ¨åˆ†äº†ï¼Œdecoderçš„è¾“å‡ºéƒ¨åˆ†ä¹Ÿå°±æ˜¯æ•´ä¸ªçš„transformerçš„è¾“å‡ºéƒ¨åˆ†ã€‚

![pic from internet](http://commcheck396.github.io/assets/img/2022_2_14/output.png)

Outputå¦‚å›¾ä¸­æ‰€ç¤ºï¼Œé¦–å…ˆç»è¿‡ä¸€æ¬¡çº¿æ€§å˜æ¢ï¼Œç„¶åSoftmaxå¾—åˆ°è¾“å‡ºçš„æ¦‚ç‡åˆ†å¸ƒï¼Œç„¶åé€šè¿‡è¯å…¸ï¼Œè¾“å‡ºæ¦‚ç‡æœ€å¤§çš„å¯¹åº”çš„å•è¯ä½œä¸ºæˆ‘ä»¬çš„é¢„æµ‹è¾“å‡ºã€‚  

åˆ°è¿™é‡Œtransformerçš„æ‰€æœ‰éƒ¨åˆ†ä¹Ÿå°±å¤§æ¦‚è¯´äº†ä¸€éäº†ã€‚ä¸‹é¢è¿™å¼ å›¾å„¿è¿˜æŒºå½¢è±¡çš„ã€‚

![pic from internet](http://commcheck396.github.io/assets/img/2022_2_14/transformer.gif)

æ‡‚äº†å—ï¼Ÿæ‡‚äº†ï¼Œä½†æ²¡å®Œå…¨æ‡‚ï¼Œä¸‹é¢å†ç»“åˆç€ä»£ç çœ‹ä¸€çœ‹å§ï¼Œçº¸ä¸Šå¾—æ¥ç»ˆè§‰æµ…ï¼Œè¿˜å¾—æ‰“å¼€VScodeã€‚  

## ä»£ç è§£æéƒ¨åˆ†

ä¾èµ–çš„librarieså¦‚ä¸‹
```python
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import math
```

æ’…batch
```python
def make_batch(sentences):
    input_batch = [[src_vocab[n] for n in sentences[0].split()]]
    output_batch = [[tgt_vocab[n] for n in sentences[1].split()]]
    target_batch = [[tgt_vocab[n] for n in sentences[2].split()]]
    return torch.LongTensor(input_batch), torch.LongTensor(output_batch), torch.LongTensor(target_batch)
# æˆ‘ä»¬è¾“å…¥çš„æ‰€æœ‰å¥å­éƒ½è¦æŒ‰ç…§[input,output,target]æ ¼å¼è¿›è¡Œè¾“å…¥
```
é¦–å…ˆè¯´mainå‡½æ•°å§
```python
if __name__ == '__main__':

    ## å¥å­çš„è¾“å…¥éƒ¨åˆ†ï¼Œå¯ä»¥è¾“å…¥å¤šç»„å¥å­ï¼Œä¸è¿‡è¦æŒ‰ç…§ä¸Šè¿°æ ¼å¼è¿›è¡Œè¾“å…¥
    sentences = ['ich mochte ein bier P', 'S i want a beer', 'i want a beer E']


    # Transformer Parameters
    # Padding Should be Zero
    ## æ„å»ºè¯è¡¨
    src_vocab = {'P': 0, 'ich': 1, 'mochte': 2, 'ein': 3, 'bier': 4} # è¾“å…¥è¯è¡¨
    src_vocab_size = len(src_vocab)

    tgt_vocab = {'P': 0, 'i': 1, 'want': 2, 'a': 3, 'beer': 4, 'S': 5, 'E': 6} # è¾“å‡ºè¯è¡¨
    tgt_vocab_size = len(tgt_vocab)

    src_len = 5 # length of source
    tgt_len = 5 # length of target

    ## æ¨¡å‹å‚æ•°
    d_model = 512  # Embedding Sizeï¼Œå°†æ¯ä¸€ä¸ªè¯embedå…¥512dimä¸­
    d_ff = 2048  # FeedForward dimensionï¼Œç¥ç»ç½‘ç»œæ·±åº¦
    d_k = d_v = 64  # dimension of K(=Q), V
    n_layers = 6  # number of Encoder of Decoder Layer
    n_heads = 8  # number of heads in Multi-Head Attention

    model = Transformer() # åˆå§‹åŒ–

    criterion = nn.CrossEntropyLoss() # regressionå¸¸ç”¨loss function
    optimizer = optim.Adam(model.parameters(), lr=0.001) # æ— è„‘Adam Optimizer

    enc_inputs, dec_inputs, target_batch = make_batch(sentences) # æ’…batchï¼Œä¸è¿‡è¿™ä¸ªä¾‹å­ä¸­åªæœ‰ä¸€ä¸ªä¾‹å­ï¼Œä¹Ÿå°±æ²¡batchä¸batchçš„è¯´æ³•äº†

    for epoch in range(20):
        optimizer.zero_grad() # åˆå§‹åŒ–gradian
        outputs, enc_self_attns, dec_self_attns, dec_enc_attns = model(enc_inputs, dec_inputs)
        loss = criterion(outputs, target_batch.contiguous().view(-1))
        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))
        loss.backward() # å›æº¯
        optimizer.step() # æ­¥è¿›

```

è¿™ä¸è¿‡åªæ˜¯ä¸€ä¸ªç©ºæ¶å­ï¼Œä¸ï¼Œè¿ç©ºæ¶å­éƒ½æ®µä¸ä¸Šï¼Œå…ˆçœ‹ä¸€ä¸‹transformeræ¶æ„å§

```python
class Transformer(nn.Module):
    def __init__(self):
        super(Transformer, self).__init__()
        self.encoder = Encoder()  ## ç¼–ç å±‚
        self.decoder = Decoder()  ## è§£ç å±‚
        self.projection = nn.Linear(d_model, tgt_vocab_size, bias=False) ## è¾“å‡ºå±‚ d_model æ˜¯æˆ‘ä»¬è§£ç å±‚æ¯ä¸ªtokenè¾“å‡ºçš„ç»´åº¦å¤§å°ï¼Œä¹‹åä¼šåšä¸€ä¸ª tgt_vocab_size å¤§å°çš„softmaxï¼Œæ ¹æ®æ¦‚ç‡å¤§å°é€‰æ‹©å•è¯
    def forward(self, enc_inputs, dec_inputs):
        ## è¿™é‡Œæœ‰ä¸¤ä¸ªæ•°æ®è¿›è¡Œè¾“å…¥ï¼Œä¸€ä¸ªæ˜¯enc_inputs å½¢çŠ¶ä¸º[batch_size, src_len]ï¼Œä¸»è¦æ˜¯ä½œä¸ºç¼–ç æ®µçš„è¾“å…¥ï¼Œä¸€ä¸ªdec_inputsï¼Œå½¢çŠ¶ä¸º[batch_size, tgt_len]ï¼Œä¸»è¦æ˜¯ä½œä¸ºè§£ç ç«¯çš„è¾“å…¥

        ## enc_inputsä½œä¸ºè¾“å…¥ å½¢çŠ¶ä¸º[batch_size, src_len]ï¼Œè¾“å‡ºç”±è‡ªå·±çš„å‡½æ•°å†…éƒ¨æŒ‡å®šï¼Œæƒ³è¦ä»€ä¹ˆæŒ‡å®šè¾“å‡ºä»€ä¹ˆï¼Œå¯ä»¥æ˜¯å…¨éƒ¨tokensçš„è¾“å‡ºï¼Œå¯ä»¥æ˜¯ç‰¹å®šæ¯ä¸€å±‚çš„è¾“å‡ºï¼›ä¹Ÿå¯ä»¥æ˜¯ä¸­é—´æŸäº›å‚æ•°çš„è¾“å‡ºï¼›
        ## enc_outputså°±æ˜¯ä¸»è¦çš„è¾“å‡ºï¼Œenc_self_attnsæ˜¯QKè½¬ç½®ç›¸ä¹˜ä¹‹åsoftmaxä¹‹åçš„çŸ©é˜µå€¼ï¼Œä»£è¡¨æ¯ä¸ªå•è¯å’Œå…¶ä»–å•è¯ç›¸å…³æ€§ï¼›
        enc_outputs, enc_self_attns = self.encoder(enc_inputs)

        ## dec_outputs æ˜¯decoderä¸»è¦è¾“å‡ºï¼Œç”¨äºåç»­çš„linearæ˜ å°„ï¼› dec_self_attnsç±»æ¯”äºenc_self_attns æ˜¯æŸ¥çœ‹æ¯ä¸ªå•è¯å¯¹decoderä¸­è¾“å…¥çš„å…¶ä½™å•è¯çš„ç›¸å…³æ€§ï¼›dec_enc_attnsæ˜¯decoderä¸­æ¯ä¸ªå•è¯å¯¹encoderä¸­æ¯ä¸ªå•è¯çš„ç›¸å…³æ€§ï¼›
        dec_outputs, dec_self_attns, dec_enc_attns = self.decoder(dec_inputs, enc_inputs, enc_outputs)

        ## dec_outputsåšæ˜ å°„åˆ°è¯è¡¨çš„æ“ä½œ
        dec_logits = self.projection(dec_outputs) # dec_logits : [batch_size x src_vocab_size x tgt_vocab_size]
        return dec_logits.view(-1, dec_logits.size(-1)), enc_self_attns, dec_self_attns, dec_enc_attns
```
è¿™ç»ˆäºèƒ½çœ‹å‡ºä¸€ç‚¹æ¶å­çš„æ ·å­äº†ï¼Œé‚£æˆ‘ä»¬å°±æŒ‰ç…§ä»£ç çš„é¡ºåºæ¥ç€å¾€ä¸‹å“ï¼Œå…ˆçœ‹encoder
```python
# Encoder éƒ¨åˆ†åŒ…å«ä¸‰ä¸ªéƒ¨åˆ†ï¼šè¯å‘é‡embeddingï¼Œä½ç½®ç¼–ç éƒ¨åˆ†ï¼Œæ³¨æ„åŠ›å±‚åŠåç»­çš„å‰é¦ˆç¥ç»ç½‘ç»œ

class Encoder(nn.Module):
    def __init__(self):
        super(Encoder, self).__init__()
        self.src_emb = nn.Embedding(src_vocab_size, d_model)  ## è¿™ä¸ªå…¶å®å°±æ˜¯å»å®šä¹‰ç”Ÿæˆä¸€ä¸ªçŸ©é˜µï¼Œå¤§å°æ˜¯ src_vocab_size * d_model
        self.pos_emb = PositionalEncoding(d_model) ## ä½ç½®ç¼–ç æƒ…å†µï¼Œè¿™é‡Œæ˜¯å›ºå®šçš„æ­£ä½™å¼¦å‡½æ•°
        self.layers = nn.ModuleList([EncoderLayer() for _ in range(n_layers)]) ## ä½¿ç”¨ModuleListå¯¹å¤šä¸ªencoderè¿›è¡Œå †å 

    def forward(self, enc_inputs):
        ## è¿™é‡Œæˆ‘ä»¬çš„ enc_inputs å½¢çŠ¶æ˜¯ï¼š [batch_size x source_len]

        ## ä¸‹é¢è¿™ä¸ªä»£ç é€šè¿‡src_embï¼Œè¿›è¡Œç´¢å¼•å®šä½ï¼Œenc_outputsè¾“å‡ºå½¢çŠ¶æ˜¯[batch_size, src_len, d_model]
        enc_outputs = self.src_emb(enc_inputs)

        ## è¿™é‡Œå°±æ˜¯ä½ç½®ç¼–ç ï¼ŒæŠŠä¸¤è€…ç›¸åŠ æ”¾å…¥åˆ°äº†è¿™ä¸ªå‡½æ•°é‡Œé¢ï¼Œä»è¿™é‡Œå¯ä»¥å»çœ‹ä¸€ä¸‹ä½ç½®ç¼–ç å‡½æ•°çš„å®ç°ï¼›
        enc_outputs = self.pos_emb(enc_outputs.transpose(0, 1)).transpose(0, 1)

        ##get_attn_pad_maskæ˜¯ä¸ºäº†å¾—åˆ°å¥å­ä¸­padçš„ä½ç½®ä¿¡æ¯ï¼Œç»™åˆ°æ¨¡å‹åé¢ï¼Œåœ¨è®¡ç®—è‡ªæ³¨æ„åŠ›å’Œäº¤äº’æ³¨æ„åŠ›çš„æ—¶å€™å»æ‰padç¬¦å·çš„å½±å“
        enc_self_attn_mask = get_attn_pad_mask(enc_inputs, enc_inputs)
        enc_self_attns = []
        for layer in self.layers:
            ## ä¾æ¬¡é€šè¿‡nä¸ªencoder layerï¼ŒæŠŠæ¯ä¸€å±‚çš„è¾“å‡ºå½“ä½œä¸‹ä¸€å±‚çš„è¾“å…¥
            enc_outputs, enc_self_attn = layer(enc_outputs, enc_self_attn_mask)
            enc_self_attns.append(enc_self_attn)
        return enc_outputs, enc_self_attns
```
ä¸‹é¢æˆ‘ä»¬ä¾æ¬¡æ¥çœ‹ä¸€ä¸‹ä¸Šé¢æåˆ°çš„å‡ ä¸ªå‡½æ•°
### PositionalEncoding
![pic from internet](http://commcheck396.github.io/assets/img/2022_2_14/f1.png)
```python
class PositionalEncoding(nn.Module):
    def __init__(self, d_model, dropout=0.1, max_len=5000):
        super(PositionalEncoding, self).__init__()

        ## å…¶å®å°±æ˜¯ç…§ç€ä¸Šé¢ç»™çš„é‚£ä¸ªæœ‰sinï¼Œcosçš„å…¬å¼å¤ç°
        ## ä»ç†è§£æ¥è®²ï¼Œéœ€è¦æ³¨æ„çš„å°±æ˜¯å¶æ•°å’Œå¥‡æ•°åœ¨å…¬å¼ä¸Šæœ‰ä¸€ä¸ªå…±åŒéƒ¨åˆ†ï¼Œæˆ‘ä»¬ä½¿ç”¨logå‡½æ•°æŠŠæ¬¡æ–¹æ‹¿ä¸‹æ¥ï¼Œæ–¹ä¾¿è®¡ç®—
        self.dropout = nn.Dropout(p=dropout)

        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)## è¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯pe[:, 0::2]è¿™ä¸ªç”¨æ³•ï¼Œå°±æ˜¯ä»0å¼€å§‹åˆ°æœ€åé¢ï¼Œè¡¥é•¿ä¸º2ï¼Œå…¶å®ä»£è¡¨çš„å°±æ˜¯å¶æ•°ä½ç½®
        pe[:, 1::2] = torch.cos(position * div_term)##è¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯pe[:, 1::2]è¿™ä¸ªç”¨æ³•ï¼Œå°±æ˜¯ä»1å¼€å§‹åˆ°æœ€åé¢ï¼Œè¡¥é•¿ä¸º2ï¼Œå…¶å®ä»£è¡¨çš„å°±æ˜¯å¥‡æ•°ä½ç½®
        ## ä¸Šé¢ä»£ç è·å–ä¹‹åå¾—åˆ°çš„pe:[max_len*d_model]

        ## ä¸‹é¢è¿™ä¸ªä»£ç ä¹‹åï¼Œæˆ‘ä»¬å¾—åˆ°çš„peå½¢çŠ¶æ˜¯ï¼š[max_len*1*d_model]
        pe = pe.unsqueeze(0).transpose(0, 1)

        self.register_buffer('pe', pe)  ## å®šä¸€ä¸ªç¼“å†²åŒºï¼Œå…¶å®ç®€å•ç†è§£ä¸ºè¿™ä¸ªå‚æ•°ä¸æ›´æ–°å°±å¯ä»¥

    def forward(self, x):
        """
        x: [seq_len, batch_size, d_model]
        """
        x = x + self.pe[:x.size(0), :]
        return self.dropout(x)

```


### get_attn_pad_mask
```python
## æ¯”å¦‚è¯´ï¼Œæˆ‘ç°åœ¨çš„å¥å­é•¿åº¦æ˜¯5ï¼Œåœ¨åé¢æ³¨æ„åŠ›æœºåˆ¶çš„éƒ¨åˆ†ï¼Œæˆ‘ä»¬åœ¨è®¡ç®—å‡ºæ¥QKè½¬ç½®é™¤ä»¥æ ¹å·ä¹‹åï¼Œsoftmaxä¹‹å‰ï¼Œæˆ‘ä»¬å¾—åˆ°çš„å½¢çŠ¶ len_input * len*input  ä»£è¡¨æ¯ä¸ªå•è¯å¯¹å…¶ä½™åŒ…å«è‡ªå·±çš„å•è¯çš„å½±å“åŠ›

## æ‰€ä»¥è¿™é‡Œæˆ‘éœ€è¦æœ‰ä¸€ä¸ªåŒç­‰å¤§å°å½¢çŠ¶çš„çŸ©é˜µï¼Œå‘Šè¯‰æˆ‘å“ªä¸ªä½ç½®æ˜¯PADéƒ¨åˆ†ï¼Œä¹‹ååœ¨è®¡ç®—è®¡ç®—softmaxä¹‹å‰ä¼šæŠŠè¿™é‡Œç½®ä¸ºæ— ç©·å¤§ï¼›

## ä¸€å®šéœ€è¦æ³¨æ„çš„æ˜¯è¿™é‡Œå¾—åˆ°çš„çŸ©é˜µå½¢çŠ¶æ˜¯batch_size x len_q x len_kï¼Œæˆ‘ä»¬æ˜¯å¯¹kä¸­çš„padç¬¦å·è¿›è¡Œæ ‡è¯†ï¼Œå¹¶æ²¡æœ‰å¯¹kä¸­çš„åšæ ‡è¯†ï¼Œå› ä¸ºæ²¡å¿…è¦

## seq_q å’Œ seq_k ä¸ä¸€å®šä¸€è‡´ï¼Œåœ¨äº¤äº’æ³¨æ„åŠ›ï¼Œqæ¥è‡ªè§£ç ç«¯ï¼Œkæ¥è‡ªç¼–ç ç«¯ï¼Œæ‰€ä»¥å‘Šè¯‰æ¨¡å‹ç¼–ç è¿™è¾¹padç¬¦å·ä¿¡æ¯å°±å¯ä»¥ï¼Œè§£ç ç«¯çš„padä¿¡æ¯åœ¨äº¤äº’æ³¨æ„åŠ›å±‚æ˜¯æ²¡æœ‰ç”¨åˆ°çš„ï¼›

def get_attn_pad_mask(seq_q, seq_k):
    batch_size, len_q = seq_q.size()
    batch_size, len_k = seq_k.size()
    # eq(zero) is PAD token
    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1)  # batch_size x 1 x len_k, one is masking
    return pad_attn_mask.expand(batch_size, len_q, len_k)  # batch_size x len_q x len_k
```

### EncoderLayer

```python
class EncoderLayer(nn.Module):
    def __init__(self):
        super(EncoderLayer, self).__init__()
        self.enc_self_attn = MultiHeadAttention() # å¤šå¤´è‡ªæ³¨æ„åŠ›
        self.pos_ffn = PoswiseFeedForwardNet() # å‰é¦ˆç¥ç»ç½‘ç»œ

    def forward(self, enc_inputs, enc_self_attn_mask):
        ## ä¸‹é¢è¿™ä¸ªå°±æ˜¯åšè‡ªæ³¨æ„åŠ›å±‚ï¼Œè¾“å…¥æ˜¯enc_inputsï¼Œå½¢çŠ¶æ˜¯[batch_size x seq_len_q x d_model] éœ€è¦æ³¨æ„çš„æ˜¯æœ€åˆå§‹çš„QKVçŸ©é˜µæ˜¯ç­‰åŒäºè¿™ä¸ªè¾“å…¥çš„
        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask) # è·å¾—å½¼æ­¤ç›¸å…³æ€§
        enc_outputs = self.pos_ffn(enc_outputs) # enc_outputs: [batch_size x len_q x d_model]
        return enc_outputs, attn

```

### MultiHeadAttention
è¿™ä¹Ÿå°±æ˜¯ä¹‹å‰é•¿ç¯‡å¤§è®ºæ¢è®¨çš„Self-attentionçš„ä¸»ä½“éƒ¨åˆ†
```python
class MultiHeadAttention(nn.Module):
    def __init__(self):
        super(MultiHeadAttention, self).__init__()
        ## è¾“å…¥è¿›æ¥çš„QKVæ˜¯ç›¸ç­‰çš„ï¼Œæˆ‘ä»¬ä¼šä½¿ç”¨æ˜ å°„linearåšä¸€ä¸ªæ˜ å°„å¾—åˆ°å‚æ•°çŸ©é˜µWq, Wk,Wv
        self.W_Q = nn.Linear(d_model, d_k * n_heads)
        self.W_K = nn.Linear(d_model, d_k * n_heads)
        self.W_V = nn.Linear(d_model, d_v * n_heads)
        self.linear = nn.Linear(n_heads * d_v, d_model)
        self.layer_norm = nn.LayerNorm(d_model)

    def forward(self, Q, K, V, attn_mask):

        ## è¿™ä¸ªå¤šå¤´åˆ†ä¸ºè¿™å‡ ä¸ªæ­¥éª¤ï¼Œé¦–å…ˆæ˜ å°„åˆ†å¤´ï¼Œç„¶åè®¡ç®—atten_scoresï¼Œç„¶åè®¡ç®—atten_value;
        ##è¾“å…¥è¿›æ¥çš„æ•°æ®å½¢çŠ¶ï¼š Q: [batch_size x len_q x d_model], K: [batch_size x len_k x d_model], V: [batch_size x len_k x d_model]
        residual, batch_size = Q, Q.size(0)
        # (B, S, D) -proj-> (B, S, D) -split-> (B, S, H, W) -trans-> (B, H, S, W)

        ##ä¸‹é¢è¿™ä¸ªå°±æ˜¯å…ˆæ˜ å°„ï¼Œååˆ†å¤´ï¼›ä¸€å®šè¦æ³¨æ„çš„æ˜¯qå’Œkåˆ†å¤´ä¹‹åç»´åº¦æ˜¯ä¸€è‡´é¢ï¼Œæ‰€ä»¥ä¸€çœ‹è¿™é‡Œéƒ½æ˜¯dk
        q_s = self.W_Q(Q).view(batch_size, -1, n_heads, d_k).transpose(1,2)  # q_s: [batch_size x n_heads x len_q x d_k]
        k_s = self.W_K(K).view(batch_size, -1, n_heads, d_k).transpose(1,2)  # k_s: [batch_size x n_heads x len_k x d_k]
        v_s = self.W_V(V).view(batch_size, -1, n_heads, d_v).transpose(1,2)  # v_s: [batch_size x n_heads x len_k x d_v]

        ## è¾“å…¥è¿›è¡Œçš„attn_maskå½¢çŠ¶æ˜¯ batch_size x len_q x len_kï¼Œç„¶åç»è¿‡ä¸‹é¢è¿™ä¸ªä»£ç å¾—åˆ° æ–°çš„attn_mask : [batch_size x n_heads x len_q x len_k]ï¼Œå°±æ˜¯æŠŠpadä¿¡æ¯é‡å¤äº†nä¸ªå¤´ä¸Š
        attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)


        ##ç„¶åæˆ‘ä»¬è®¡ç®— ScaledDotProductAttention è¿™ä¸ªå‡½æ•°ï¼Œå¾—åˆ°çš„ç»“æœæœ‰ä¸¤ä¸ªï¼šcontext: [batch_size x n_heads x len_q x d_v], attn: [batch_size x n_heads x len_q x len_k]
        context, attn = ScaledDotProductAttention()(q_s, k_s, v_s, attn_mask)
        context = context.transpose(1, 2).contiguous().view(batch_size, -1, n_heads * d_v) # context: [batch_size x len_q x n_heads * d_v]
        output = self.linear(context)
        return self.layer_norm(output + residual), attn # output: [batch_size x len_q x d_model]

```

### ScaledDotProductAttention
![pic from internet](http://commcheck396.github.io/assets/img/2022_2_14/encoderlayer.png)
```python
class ScaledDotProductAttention(nn.Module):
    def __init__(self):
        super(ScaledDotProductAttention, self).__init__()

    def forward(self, Q, K, V, attn_mask):
        ## è¾“å…¥è¿›æ¥çš„ç»´åº¦åˆ†åˆ«æ˜¯ [batch_size x n_heads x len_q x d_k]  Kï¼š [batch_size x n_heads x len_k x d_k]  V: [batch_size x n_heads x len_k x d_v]
        ##é¦–å…ˆç»è¿‡matmulå‡½æ•°å¾—åˆ°çš„scoreså½¢çŠ¶æ˜¯ : [batch_size x n_heads x len_q x len_k]
        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)

        ## ç„¶åå…³é”®è¯åœ°æ–¹æ¥äº†ï¼Œä¸‹é¢è¿™ä¸ªå°±æ˜¯ç”¨åˆ°äº†æˆ‘ä»¬ä¹‹å‰é‡ç‚¹è®²çš„attn_maskï¼ŒæŠŠè¢«maskçš„åœ°æ–¹ç½®ä¸ºæ— é™å°ï¼Œsoftmaxä¹‹ååŸºæœ¬å°±æ˜¯0ï¼Œå¯¹qçš„å•è¯ä¸èµ·ä½œç”¨
        scores.masked_fill_(attn_mask, -1e9) # Fills elements of self tensor with value where mask is one.
        attn = nn.Softmax(dim=-1)(scores)
        context = torch.matmul(attn, V)
        return context, attn
```

### PoswiseFeedForwardNet
å¸¸è§„æ“ä½œï¼ŒåŒå±‚conv
```python
class PoswiseFeedForwardNet(nn.Module):
    def __init__(self):
        super(PoswiseFeedForwardNet, self).__init__()
        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)
        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)
        self.layer_norm = nn.LayerNorm(d_model)

    def forward(self, inputs):
        residual = inputs # inputs : [batch_size, len_q, d_model]
        output = nn.ReLU()(self.conv1(inputs.transpose(1, 2)))
        output = self.conv2(output).transpose(1, 2)
        return self.layer_norm(output + residual)
```
encoderå·®ä¸å¤šå°±è¿™ä¹ˆå¤šï¼Œä¸‹é¢æ˜¯decoderï¼Œå’Œencoderç±»ä¼¼ï¼Œä»…æœ‰å°‘é‡è¡¥å……
### Decoder
```python
class Decoder(nn.Module):
    def __init__(self):
        super(Decoder, self).__init__()
        self.tgt_emb = nn.Embedding(tgt_vocab_size, d_model)
        self.pos_emb = PositionalEncoding(d_model)
        self.layers = nn.ModuleList([DecoderLayer() for _ in range(n_layers)])

    def forward(self, dec_inputs, enc_inputs, enc_outputs): # dec_inputs : [batch_size x target_len]
        dec_outputs = self.tgt_emb(dec_inputs)  # [batch_size, tgt_len, d_model]
        dec_outputs = self.pos_emb(dec_outputs.transpose(0, 1)).transpose(0, 1) # [batch_size, tgt_len, d_model]

        ## get_attn_pad_mask è‡ªæ³¨æ„åŠ›å±‚çš„æ—¶å€™çš„pad éƒ¨åˆ†
        dec_self_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs)

        ## get_attn_subsequent_mask è¿™ä¸ªåšçš„æ˜¯è‡ªæ³¨æ„å±‚çš„maskéƒ¨åˆ†ï¼Œå°±æ˜¯å½“å‰å•è¯ä¹‹åçœ‹ä¸åˆ°ï¼Œä½¿ç”¨ä¸€ä¸ªä¸Šä¸‰è§’ä¸º1çš„çŸ©é˜µ
        dec_self_attn_subsequent_mask = get_attn_subsequent_mask(dec_inputs)

        ## ä¸¤ä¸ªçŸ©é˜µç›¸åŠ ï¼Œå¤§äº0çš„ä¸º1ï¼Œä¸å¤§äº0çš„ä¸º0ï¼Œä¸º1çš„åœ¨ä¹‹åå°±ä¼šè¢«fillåˆ°æ— é™å°
        dec_self_attn_mask = torch.gt((dec_self_attn_pad_mask + dec_self_attn_subsequent_mask), 0)


        ## è¿™ä¸ªåšçš„æ˜¯äº¤äº’æ³¨æ„åŠ›æœºåˆ¶ä¸­çš„maskçŸ©é˜µï¼Œencçš„è¾“å…¥æ˜¯kï¼Œæˆ‘å»çœ‹è¿™ä¸ªké‡Œé¢å“ªäº›æ˜¯padç¬¦å·ï¼Œç»™åˆ°åé¢çš„æ¨¡å‹
        dec_enc_attn_mask = get_attn_pad_mask(dec_inputs, enc_inputs)

        dec_self_attns, dec_enc_attns = [], []
        for layer in self.layers:
            dec_outputs, dec_self_attn, dec_enc_attn = layer(dec_outputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask)
            dec_self_attns.append(dec_self_attn)
            dec_enc_attns.append(dec_enc_attn)
        return dec_outputs, dec_self_attns, dec_enc_attns
```

### DecoderLayer

```python
class DecoderLayer(nn.Module):
    def __init__(self):
        super(DecoderLayer, self).__init__()
        self.dec_self_attn = MultiHeadAttention()
        self.dec_enc_attn = MultiHeadAttention()
        self.pos_ffn = PoswiseFeedForwardNet()

    def forward(self, dec_inputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask):
        dec_outputs, dec_self_attn = self.dec_self_attn(dec_inputs, dec_inputs, dec_inputs, dec_self_attn_mask)
        dec_outputs, dec_enc_attn = self.dec_enc_attn(dec_outputs, enc_outputs, enc_outputs, dec_enc_attn_mask)
        dec_outputs = self.pos_ffn(dec_outputs)
        return dec_outputs, dec_self_attn, dec_enc_attn
```

### get_attn_subsequent_mask
è·å–subsequent mask
```python
def get_attn_subsequent_mask(seq):
    """
    seq: [batch_size, tgt_len]
    """
    attn_shape = [seq.size(0), seq.size(1), seq.size(1)]
    # attn_shape: [batch_size, tgt_len, tgt_len]
    subsequence_mask = np.triu(np.ones(attn_shape), k=1)  # ç”Ÿæˆä¸€ä¸ªä¸Šä¸‰è§’çŸ©é˜µ
    subsequence_mask = torch.from_numpy(subsequence_mask).byte()
    return subsequence_mask  # [batch_size, tgt_len, tgt_len]
```

æ€»ç®—æ˜¯ä»å¤´åˆ°å°¾æ¢³ç†äº†ä¸€éï¼Œæœ‰äº›åœ°æ–¹è¿˜æ˜¯æœ‰äº›æ¨¡æ£±ä¸¤å¯ï¼Œæ²¡å…³ç³»ï¼Œä¹‹åå†ç ”ç©¶ç ”ç©¶ï¼Œç´¯äº†ä¸æƒ³çœ‹äº†ï¼Œæ”¶æ‹¾ä¸œè¥¿å»äº†ã€‚  

å¯’å‡è¿‡å¾—çœŸå¿«ï¼Œæ˜å¤©åˆå¼€å­¦äº†ã€‚  

å”‰ï¼ŒåŠ æ²¹å§ï¼Œåå¤§ç‰¢å»å–½ï¼Œéš¾é¡¶ğŸ˜­ã€‚